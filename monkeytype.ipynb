{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings for Monkeytype:\n",
    " - `words` or `quote` so we can get the WPM without having to wait for the test to end\n",
    " - `show all lines:on` combined with the previous setting allows us to complete the test with a single screenshot\n",
    " - `caret style:off` avoids including the caret as a character in the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pyautogui\n",
    "from mss import mss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "110 WPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images for template matching\n",
    "globe = cv2.imread('globe.PNG')\n",
    "restart = cv2.imread('restart.PNG')\n",
    "\n",
    "# Change focus to main monitor\n",
    "pyautogui.click(0, 540)\n",
    "pyautogui.press('backspace')\n",
    "\n",
    "with mss() as sct:\n",
    "    # Use the 1st monitor\n",
    "    monitor_1 = sct.monitors[1]\n",
    "    # Grab screenshot and reduce to 3 channels for template matching\n",
    "    sct_img = np.array(sct.grab(monitor_1))[:,:,:3]\n",
    "\n",
    "    # Template matching of icons to get testing area\n",
    "    top = cv2.matchTemplate(sct_img, globe, cv2.TM_CCOEFF_NORMED)\n",
    "    bot = cv2.matchTemplate(sct_img, restart, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    _, _, _, max_loc1 = cv2.minMaxLoc(top)\n",
    "    _, _, _, max_loc2 = cv2.minMaxLoc(bot)\n",
    "\n",
    "    # Crop image and get string using pytesseract\n",
    "    text = pytesseract.image_to_string(sct_img[max_loc1[1] + 30:max_loc2[1],:,:])\n",
    "\n",
    "    # Typing\n",
    "    for i in text:\n",
    "        if(i == '\\n'):\n",
    "            pyautogui.press(' ')\n",
    "        else:\n",
    "            pyautogui.press(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~9,000 WPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images for template matching\n",
    "globe = cv2.imread('globe.PNG')\n",
    "restart = cv2.imread('restart.PNG')\n",
    "\n",
    "# change focus to main monitor\n",
    "pyautogui.click(0, 540)\n",
    "pyautogui.press('backspace')\n",
    "\n",
    "with mss() as sct:\n",
    "    # Use the 1st monitor\n",
    "    monitor_1 = sct.monitors[1]\n",
    "    # Grab screenshot and reduce to 3 channels for template matching\n",
    "    sct_img = np.array(sct.grab(monitor_1))[:,:,:3]\n",
    "\n",
    "    # Template matching of icons to get testing area\n",
    "    top = cv2.matchTemplate(sct_img, globe, cv2.TM_CCOEFF_NORMED)\n",
    "    bot = cv2.matchTemplate(sct_img, restart, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    _, _, _, max_loc1 = cv2.minMaxLoc(top)\n",
    "    _, _, _, max_loc2 = cv2.minMaxLoc(bot)\n",
    "\n",
    "    # Crop image and get string using pytesseract\n",
    "    text = pytesseract.image_to_string(sct_img[max_loc1[1] + 30:max_loc2[1],:,:])\n",
    "    text = text[:-1].replace('\\n', ' ')\n",
    "\n",
    "    # Tpying\n",
    "    pyautogui.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('minimal_datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26a1d7ea2587472376a9421b02b51193dfd5c396bac708b8b6ee57ef6dd687ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
